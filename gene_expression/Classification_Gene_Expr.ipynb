{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import (RandomForestClassifier,\n",
    "                              GradientBoostingClassifier)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, SMOTENC\n",
    "from imblearn.pipeline import Pipeline\n",
    "from scipy.sparse import hstack\n",
    "import warnings\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, roc_auc_score, balanced_accuracy_score\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/subashkhanal/Desktop/BMI633/ADNI_Genetics/Genomics/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "#Gene ranking based on ttest\n",
    "ttest = read_csv(os.path.join(data_path,'t_test_0.05_geneExpr_Unfiltered_bl.csv')).sort_values('CN_AD')\n",
    "important_probes = ttest.sort_values('CN_AD'+'_c')['Gene'][0:N] #suffix _c to use the FDR corrected p values\n",
    "\n",
    "#Gene Expression Data\n",
    "Gene_expr = read_csv(os.path.join(data_path,'Unfiltered_gene_expr_dx.csv'),low_memory=False)\n",
    "Gene_expr = Gene_expr[['Unnamed: 0','AGE','PTGENDER','PTEDUCAT','DX_bl']+list(important_probes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>DX_bl</th>\n",
       "      <th>11761978_at_ARHGEF12</th>\n",
       "      <th>11754382_a_at_SMIM5</th>\n",
       "      <th>11755705_a_at_SMIM5</th>\n",
       "      <th>11758611_s_at_TRIM10</th>\n",
       "      <th>11724079_s_at_E2F2</th>\n",
       "      <th>...</th>\n",
       "      <th>11743992_at_UBE2O</th>\n",
       "      <th>11716563_s_at_AIMP2</th>\n",
       "      <th>11744861_a_at_DHRS7</th>\n",
       "      <th>AFFX-r2-Bs-phe-3_at_nan</th>\n",
       "      <th>11750558_s_at_ZNF271</th>\n",
       "      <th>11731447_x_at_SNCA</th>\n",
       "      <th>11734736_a_at_FAR1</th>\n",
       "      <th>11719828_x_at_QPCT</th>\n",
       "      <th>11750143_a_at_PIGZ</th>\n",
       "      <th>11732501_a_at_TMOD1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116_S_1249</td>\n",
       "      <td>70.8</td>\n",
       "      <td>Female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>4.573</td>\n",
       "      <td>7.203</td>\n",
       "      <td>7.587</td>\n",
       "      <td>7.559</td>\n",
       "      <td>9.251</td>\n",
       "      <td>...</td>\n",
       "      <td>5.582</td>\n",
       "      <td>7.690</td>\n",
       "      <td>10.620</td>\n",
       "      <td>8.780</td>\n",
       "      <td>3.804</td>\n",
       "      <td>9.955</td>\n",
       "      <td>3.541</td>\n",
       "      <td>9.176</td>\n",
       "      <td>2.229</td>\n",
       "      <td>6.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>037_S_4410</td>\n",
       "      <td>69.1</td>\n",
       "      <td>Female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>4.969</td>\n",
       "      <td>5.378</td>\n",
       "      <td>5.535</td>\n",
       "      <td>5.297</td>\n",
       "      <td>8.335</td>\n",
       "      <td>...</td>\n",
       "      <td>4.828</td>\n",
       "      <td>7.919</td>\n",
       "      <td>10.619</td>\n",
       "      <td>8.722</td>\n",
       "      <td>4.303</td>\n",
       "      <td>9.469</td>\n",
       "      <td>4.960</td>\n",
       "      <td>8.711</td>\n",
       "      <td>1.998</td>\n",
       "      <td>5.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006_S_4153</td>\n",
       "      <td>79.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>4.805</td>\n",
       "      <td>6.094</td>\n",
       "      <td>6.355</td>\n",
       "      <td>6.496</td>\n",
       "      <td>8.940</td>\n",
       "      <td>...</td>\n",
       "      <td>5.132</td>\n",
       "      <td>7.584</td>\n",
       "      <td>10.609</td>\n",
       "      <td>8.995</td>\n",
       "      <td>3.459</td>\n",
       "      <td>8.780</td>\n",
       "      <td>3.147</td>\n",
       "      <td>9.201</td>\n",
       "      <td>2.223</td>\n",
       "      <td>5.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116_S_1232</td>\n",
       "      <td>72.1</td>\n",
       "      <td>Female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>6.287</td>\n",
       "      <td>8.110</td>\n",
       "      <td>8.376</td>\n",
       "      <td>9.000</td>\n",
       "      <td>10.421</td>\n",
       "      <td>...</td>\n",
       "      <td>6.852</td>\n",
       "      <td>7.967</td>\n",
       "      <td>10.519</td>\n",
       "      <td>9.449</td>\n",
       "      <td>3.327</td>\n",
       "      <td>11.047</td>\n",
       "      <td>2.753</td>\n",
       "      <td>8.706</td>\n",
       "      <td>2.570</td>\n",
       "      <td>8.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>099_S_4205</td>\n",
       "      <td>81.4</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>EMCI</td>\n",
       "      <td>3.969</td>\n",
       "      <td>5.913</td>\n",
       "      <td>6.209</td>\n",
       "      <td>5.448</td>\n",
       "      <td>8.424</td>\n",
       "      <td>...</td>\n",
       "      <td>4.955</td>\n",
       "      <td>7.649</td>\n",
       "      <td>10.623</td>\n",
       "      <td>8.852</td>\n",
       "      <td>3.480</td>\n",
       "      <td>8.790</td>\n",
       "      <td>3.891</td>\n",
       "      <td>9.160</td>\n",
       "      <td>2.310</td>\n",
       "      <td>4.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>009_S_2381</td>\n",
       "      <td>69.1</td>\n",
       "      <td>Male</td>\n",
       "      <td>16.0</td>\n",
       "      <td>EMCI</td>\n",
       "      <td>6.367</td>\n",
       "      <td>8.106</td>\n",
       "      <td>8.419</td>\n",
       "      <td>8.372</td>\n",
       "      <td>10.166</td>\n",
       "      <td>...</td>\n",
       "      <td>5.808</td>\n",
       "      <td>8.165</td>\n",
       "      <td>10.715</td>\n",
       "      <td>10.313</td>\n",
       "      <td>3.373</td>\n",
       "      <td>10.318</td>\n",
       "      <td>3.506</td>\n",
       "      <td>9.164</td>\n",
       "      <td>2.408</td>\n",
       "      <td>6.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>053_S_4557</td>\n",
       "      <td>83.3</td>\n",
       "      <td>Female</td>\n",
       "      <td>12.0</td>\n",
       "      <td>EMCI</td>\n",
       "      <td>5.978</td>\n",
       "      <td>7.691</td>\n",
       "      <td>8.061</td>\n",
       "      <td>8.452</td>\n",
       "      <td>9.639</td>\n",
       "      <td>...</td>\n",
       "      <td>5.818</td>\n",
       "      <td>7.985</td>\n",
       "      <td>10.610</td>\n",
       "      <td>9.692</td>\n",
       "      <td>3.722</td>\n",
       "      <td>10.042</td>\n",
       "      <td>2.983</td>\n",
       "      <td>8.956</td>\n",
       "      <td>2.404</td>\n",
       "      <td>6.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>073_S_4300</td>\n",
       "      <td>80.6</td>\n",
       "      <td>Female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>LMCI</td>\n",
       "      <td>5.755</td>\n",
       "      <td>7.884</td>\n",
       "      <td>8.089</td>\n",
       "      <td>8.792</td>\n",
       "      <td>10.004</td>\n",
       "      <td>...</td>\n",
       "      <td>6.842</td>\n",
       "      <td>8.074</td>\n",
       "      <td>10.284</td>\n",
       "      <td>9.392</td>\n",
       "      <td>3.905</td>\n",
       "      <td>10.786</td>\n",
       "      <td>4.011</td>\n",
       "      <td>8.702</td>\n",
       "      <td>2.359</td>\n",
       "      <td>7.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>041_S_4014</td>\n",
       "      <td>80.7</td>\n",
       "      <td>Male</td>\n",
       "      <td>16.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>5.293</td>\n",
       "      <td>7.708</td>\n",
       "      <td>8.010</td>\n",
       "      <td>7.422</td>\n",
       "      <td>9.114</td>\n",
       "      <td>...</td>\n",
       "      <td>5.800</td>\n",
       "      <td>8.107</td>\n",
       "      <td>10.337</td>\n",
       "      <td>10.223</td>\n",
       "      <td>3.286</td>\n",
       "      <td>9.392</td>\n",
       "      <td>3.142</td>\n",
       "      <td>8.212</td>\n",
       "      <td>2.619</td>\n",
       "      <td>5.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>007_S_0101</td>\n",
       "      <td>73.6</td>\n",
       "      <td>Male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>LMCI</td>\n",
       "      <td>3.837</td>\n",
       "      <td>5.745</td>\n",
       "      <td>6.188</td>\n",
       "      <td>5.820</td>\n",
       "      <td>8.196</td>\n",
       "      <td>...</td>\n",
       "      <td>4.764</td>\n",
       "      <td>7.938</td>\n",
       "      <td>10.540</td>\n",
       "      <td>9.141</td>\n",
       "      <td>3.406</td>\n",
       "      <td>8.540</td>\n",
       "      <td>3.118</td>\n",
       "      <td>8.866</td>\n",
       "      <td>2.240</td>\n",
       "      <td>5.314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   AGE PTGENDER  PTEDUCAT DX_bl  11761978_at_ARHGEF12  \\\n",
       "0    116_S_1249  70.8   Female      15.0    CN                 4.573   \n",
       "1    037_S_4410  69.1   Female      14.0    CN                 4.969   \n",
       "2    006_S_4153  79.3     Male      20.0    AD                 4.805   \n",
       "3    116_S_1232  72.1   Female      14.0    CN                 6.287   \n",
       "4    099_S_4205  81.4   Female      18.0  EMCI                 3.969   \n",
       "..          ...   ...      ...       ...   ...                   ...   \n",
       "739  009_S_2381  69.1     Male      16.0  EMCI                 6.367   \n",
       "740  053_S_4557  83.3   Female      12.0  EMCI                 5.978   \n",
       "741  073_S_4300  80.6   Female      16.0  LMCI                 5.755   \n",
       "742  041_S_4014  80.7     Male      16.0    CN                 5.293   \n",
       "743  007_S_0101  73.6     Male      18.0  LMCI                 3.837   \n",
       "\n",
       "     11754382_a_at_SMIM5  11755705_a_at_SMIM5  11758611_s_at_TRIM10  \\\n",
       "0                  7.203                7.587                 7.559   \n",
       "1                  5.378                5.535                 5.297   \n",
       "2                  6.094                6.355                 6.496   \n",
       "3                  8.110                8.376                 9.000   \n",
       "4                  5.913                6.209                 5.448   \n",
       "..                   ...                  ...                   ...   \n",
       "739                8.106                8.419                 8.372   \n",
       "740                7.691                8.061                 8.452   \n",
       "741                7.884                8.089                 8.792   \n",
       "742                7.708                8.010                 7.422   \n",
       "743                5.745                6.188                 5.820   \n",
       "\n",
       "     11724079_s_at_E2F2  ...  11743992_at_UBE2O  11716563_s_at_AIMP2  \\\n",
       "0                 9.251  ...              5.582                7.690   \n",
       "1                 8.335  ...              4.828                7.919   \n",
       "2                 8.940  ...              5.132                7.584   \n",
       "3                10.421  ...              6.852                7.967   \n",
       "4                 8.424  ...              4.955                7.649   \n",
       "..                  ...  ...                ...                  ...   \n",
       "739              10.166  ...              5.808                8.165   \n",
       "740               9.639  ...              5.818                7.985   \n",
       "741              10.004  ...              6.842                8.074   \n",
       "742               9.114  ...              5.800                8.107   \n",
       "743               8.196  ...              4.764                7.938   \n",
       "\n",
       "     11744861_a_at_DHRS7  AFFX-r2-Bs-phe-3_at_nan  11750558_s_at_ZNF271  \\\n",
       "0                 10.620                    8.780                 3.804   \n",
       "1                 10.619                    8.722                 4.303   \n",
       "2                 10.609                    8.995                 3.459   \n",
       "3                 10.519                    9.449                 3.327   \n",
       "4                 10.623                    8.852                 3.480   \n",
       "..                   ...                      ...                   ...   \n",
       "739               10.715                   10.313                 3.373   \n",
       "740               10.610                    9.692                 3.722   \n",
       "741               10.284                    9.392                 3.905   \n",
       "742               10.337                   10.223                 3.286   \n",
       "743               10.540                    9.141                 3.406   \n",
       "\n",
       "     11731447_x_at_SNCA  11734736_a_at_FAR1  11719828_x_at_QPCT  \\\n",
       "0                 9.955               3.541               9.176   \n",
       "1                 9.469               4.960               8.711   \n",
       "2                 8.780               3.147               9.201   \n",
       "3                11.047               2.753               8.706   \n",
       "4                 8.790               3.891               9.160   \n",
       "..                  ...                 ...                 ...   \n",
       "739              10.318               3.506               9.164   \n",
       "740              10.042               2.983               8.956   \n",
       "741              10.786               4.011               8.702   \n",
       "742               9.392               3.142               8.212   \n",
       "743               8.540               3.118               8.866   \n",
       "\n",
       "     11750143_a_at_PIGZ  11732501_a_at_TMOD1  \n",
       "0                 2.229                6.533  \n",
       "1                 1.998                5.096  \n",
       "2                 2.223                5.210  \n",
       "3                 2.570                8.093  \n",
       "4                 2.310                4.909  \n",
       "..                  ...                  ...  \n",
       "739               2.408                6.686  \n",
       "740               2.404                6.847  \n",
       "741               2.359                7.454  \n",
       "742               2.619                5.389  \n",
       "743               2.240                5.314  \n",
       "\n",
       "[744 rows x 55 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gene_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'CN': 260, 'LMCI': 225, 'EMCI': 215, 'AD': 43})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>11761978_at_ARHGEF12</th>\n",
       "      <th>11754382_a_at_SMIM5</th>\n",
       "      <th>11755705_a_at_SMIM5</th>\n",
       "      <th>11758611_s_at_TRIM10</th>\n",
       "      <th>11724079_s_at_E2F2</th>\n",
       "      <th>11752515_a_at_ODC1</th>\n",
       "      <th>11750580_x_at_ARHGEF12</th>\n",
       "      <th>...</th>\n",
       "      <th>11743992_at_UBE2O</th>\n",
       "      <th>11716563_s_at_AIMP2</th>\n",
       "      <th>11744861_a_at_DHRS7</th>\n",
       "      <th>AFFX-r2-Bs-phe-3_at_nan</th>\n",
       "      <th>11750558_s_at_ZNF271</th>\n",
       "      <th>11731447_x_at_SNCA</th>\n",
       "      <th>11734736_a_at_FAR1</th>\n",
       "      <th>11719828_x_at_QPCT</th>\n",
       "      <th>11750143_a_at_PIGZ</th>\n",
       "      <th>11732501_a_at_TMOD1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.8</td>\n",
       "      <td>Female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.573</td>\n",
       "      <td>7.203</td>\n",
       "      <td>7.587</td>\n",
       "      <td>7.559</td>\n",
       "      <td>9.251</td>\n",
       "      <td>8.499</td>\n",
       "      <td>4.948</td>\n",
       "      <td>...</td>\n",
       "      <td>5.582</td>\n",
       "      <td>7.690</td>\n",
       "      <td>10.620</td>\n",
       "      <td>8.780</td>\n",
       "      <td>3.804</td>\n",
       "      <td>9.955</td>\n",
       "      <td>3.541</td>\n",
       "      <td>9.176</td>\n",
       "      <td>2.229</td>\n",
       "      <td>6.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.1</td>\n",
       "      <td>Female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.969</td>\n",
       "      <td>5.378</td>\n",
       "      <td>5.535</td>\n",
       "      <td>5.297</td>\n",
       "      <td>8.335</td>\n",
       "      <td>8.261</td>\n",
       "      <td>4.934</td>\n",
       "      <td>...</td>\n",
       "      <td>4.828</td>\n",
       "      <td>7.919</td>\n",
       "      <td>10.619</td>\n",
       "      <td>8.722</td>\n",
       "      <td>4.303</td>\n",
       "      <td>9.469</td>\n",
       "      <td>4.960</td>\n",
       "      <td>8.711</td>\n",
       "      <td>1.998</td>\n",
       "      <td>5.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.805</td>\n",
       "      <td>6.094</td>\n",
       "      <td>6.355</td>\n",
       "      <td>6.496</td>\n",
       "      <td>8.940</td>\n",
       "      <td>8.294</td>\n",
       "      <td>4.903</td>\n",
       "      <td>...</td>\n",
       "      <td>5.132</td>\n",
       "      <td>7.584</td>\n",
       "      <td>10.609</td>\n",
       "      <td>8.995</td>\n",
       "      <td>3.459</td>\n",
       "      <td>8.780</td>\n",
       "      <td>3.147</td>\n",
       "      <td>9.201</td>\n",
       "      <td>2.223</td>\n",
       "      <td>5.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.1</td>\n",
       "      <td>Female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.287</td>\n",
       "      <td>8.110</td>\n",
       "      <td>8.376</td>\n",
       "      <td>9.000</td>\n",
       "      <td>10.421</td>\n",
       "      <td>8.859</td>\n",
       "      <td>6.282</td>\n",
       "      <td>...</td>\n",
       "      <td>6.852</td>\n",
       "      <td>7.967</td>\n",
       "      <td>10.519</td>\n",
       "      <td>9.449</td>\n",
       "      <td>3.327</td>\n",
       "      <td>11.047</td>\n",
       "      <td>2.753</td>\n",
       "      <td>8.706</td>\n",
       "      <td>2.570</td>\n",
       "      <td>8.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84.1</td>\n",
       "      <td>Male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.102</td>\n",
       "      <td>7.619</td>\n",
       "      <td>7.938</td>\n",
       "      <td>7.256</td>\n",
       "      <td>9.904</td>\n",
       "      <td>8.538</td>\n",
       "      <td>5.469</td>\n",
       "      <td>...</td>\n",
       "      <td>6.191</td>\n",
       "      <td>8.175</td>\n",
       "      <td>10.621</td>\n",
       "      <td>10.572</td>\n",
       "      <td>3.225</td>\n",
       "      <td>9.509</td>\n",
       "      <td>2.883</td>\n",
       "      <td>8.694</td>\n",
       "      <td>2.319</td>\n",
       "      <td>6.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>72.9</td>\n",
       "      <td>Male</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.065</td>\n",
       "      <td>8.365</td>\n",
       "      <td>8.638</td>\n",
       "      <td>8.293</td>\n",
       "      <td>9.558</td>\n",
       "      <td>8.960</td>\n",
       "      <td>5.385</td>\n",
       "      <td>...</td>\n",
       "      <td>6.196</td>\n",
       "      <td>8.154</td>\n",
       "      <td>10.425</td>\n",
       "      <td>10.173</td>\n",
       "      <td>3.025</td>\n",
       "      <td>10.702</td>\n",
       "      <td>2.896</td>\n",
       "      <td>8.400</td>\n",
       "      <td>2.279</td>\n",
       "      <td>7.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>73.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.028</td>\n",
       "      <td>6.700</td>\n",
       "      <td>6.944</td>\n",
       "      <td>7.562</td>\n",
       "      <td>9.298</td>\n",
       "      <td>7.921</td>\n",
       "      <td>4.313</td>\n",
       "      <td>...</td>\n",
       "      <td>5.440</td>\n",
       "      <td>7.756</td>\n",
       "      <td>10.620</td>\n",
       "      <td>9.253</td>\n",
       "      <td>3.700</td>\n",
       "      <td>10.349</td>\n",
       "      <td>3.410</td>\n",
       "      <td>9.109</td>\n",
       "      <td>2.180</td>\n",
       "      <td>6.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>72.6</td>\n",
       "      <td>Male</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.631</td>\n",
       "      <td>7.049</td>\n",
       "      <td>7.388</td>\n",
       "      <td>8.292</td>\n",
       "      <td>10.198</td>\n",
       "      <td>9.062</td>\n",
       "      <td>5.889</td>\n",
       "      <td>...</td>\n",
       "      <td>6.036</td>\n",
       "      <td>8.185</td>\n",
       "      <td>10.586</td>\n",
       "      <td>9.575</td>\n",
       "      <td>3.311</td>\n",
       "      <td>10.527</td>\n",
       "      <td>4.563</td>\n",
       "      <td>8.842</td>\n",
       "      <td>2.601</td>\n",
       "      <td>6.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>84.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.563</td>\n",
       "      <td>7.017</td>\n",
       "      <td>7.071</td>\n",
       "      <td>7.277</td>\n",
       "      <td>9.013</td>\n",
       "      <td>8.695</td>\n",
       "      <td>4.524</td>\n",
       "      <td>...</td>\n",
       "      <td>6.030</td>\n",
       "      <td>8.120</td>\n",
       "      <td>10.547</td>\n",
       "      <td>10.113</td>\n",
       "      <td>3.392</td>\n",
       "      <td>9.657</td>\n",
       "      <td>2.563</td>\n",
       "      <td>8.893</td>\n",
       "      <td>2.389</td>\n",
       "      <td>5.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>80.7</td>\n",
       "      <td>Male</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.293</td>\n",
       "      <td>7.708</td>\n",
       "      <td>8.010</td>\n",
       "      <td>7.422</td>\n",
       "      <td>9.114</td>\n",
       "      <td>8.002</td>\n",
       "      <td>5.620</td>\n",
       "      <td>...</td>\n",
       "      <td>5.800</td>\n",
       "      <td>8.107</td>\n",
       "      <td>10.337</td>\n",
       "      <td>10.223</td>\n",
       "      <td>3.286</td>\n",
       "      <td>9.392</td>\n",
       "      <td>3.142</td>\n",
       "      <td>8.212</td>\n",
       "      <td>2.619</td>\n",
       "      <td>5.389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AGE PTGENDER  PTEDUCAT  11761978_at_ARHGEF12  11754382_a_at_SMIM5  \\\n",
       "0    70.8   Female      15.0                 4.573                7.203   \n",
       "1    69.1   Female      14.0                 4.969                5.378   \n",
       "2    79.3     Male      20.0                 4.805                6.094   \n",
       "3    72.1   Female      14.0                 6.287                8.110   \n",
       "8    84.1     Male      19.0                 5.102                7.619   \n",
       "..    ...      ...       ...                   ...                  ...   \n",
       "730  72.9     Male      16.0                 5.065                8.365   \n",
       "731  73.0   Female      16.0                 4.028                6.700   \n",
       "732  72.6     Male      12.0                 5.631                7.049   \n",
       "734  84.3     Male      17.0                 4.563                7.017   \n",
       "742  80.7     Male      16.0                 5.293                7.708   \n",
       "\n",
       "     11755705_a_at_SMIM5  11758611_s_at_TRIM10  11724079_s_at_E2F2  \\\n",
       "0                  7.587                 7.559               9.251   \n",
       "1                  5.535                 5.297               8.335   \n",
       "2                  6.355                 6.496               8.940   \n",
       "3                  8.376                 9.000              10.421   \n",
       "8                  7.938                 7.256               9.904   \n",
       "..                   ...                   ...                 ...   \n",
       "730                8.638                 8.293               9.558   \n",
       "731                6.944                 7.562               9.298   \n",
       "732                7.388                 8.292              10.198   \n",
       "734                7.071                 7.277               9.013   \n",
       "742                8.010                 7.422               9.114   \n",
       "\n",
       "     11752515_a_at_ODC1  11750580_x_at_ARHGEF12  ...  11743992_at_UBE2O  \\\n",
       "0                 8.499                   4.948  ...              5.582   \n",
       "1                 8.261                   4.934  ...              4.828   \n",
       "2                 8.294                   4.903  ...              5.132   \n",
       "3                 8.859                   6.282  ...              6.852   \n",
       "8                 8.538                   5.469  ...              6.191   \n",
       "..                  ...                     ...  ...                ...   \n",
       "730               8.960                   5.385  ...              6.196   \n",
       "731               7.921                   4.313  ...              5.440   \n",
       "732               9.062                   5.889  ...              6.036   \n",
       "734               8.695                   4.524  ...              6.030   \n",
       "742               8.002                   5.620  ...              5.800   \n",
       "\n",
       "     11716563_s_at_AIMP2  11744861_a_at_DHRS7  AFFX-r2-Bs-phe-3_at_nan  \\\n",
       "0                  7.690               10.620                    8.780   \n",
       "1                  7.919               10.619                    8.722   \n",
       "2                  7.584               10.609                    8.995   \n",
       "3                  7.967               10.519                    9.449   \n",
       "8                  8.175               10.621                   10.572   \n",
       "..                   ...                  ...                      ...   \n",
       "730                8.154               10.425                   10.173   \n",
       "731                7.756               10.620                    9.253   \n",
       "732                8.185               10.586                    9.575   \n",
       "734                8.120               10.547                   10.113   \n",
       "742                8.107               10.337                   10.223   \n",
       "\n",
       "     11750558_s_at_ZNF271  11731447_x_at_SNCA  11734736_a_at_FAR1  \\\n",
       "0                   3.804               9.955               3.541   \n",
       "1                   4.303               9.469               4.960   \n",
       "2                   3.459               8.780               3.147   \n",
       "3                   3.327              11.047               2.753   \n",
       "8                   3.225               9.509               2.883   \n",
       "..                    ...                 ...                 ...   \n",
       "730                 3.025              10.702               2.896   \n",
       "731                 3.700              10.349               3.410   \n",
       "732                 3.311              10.527               4.563   \n",
       "734                 3.392               9.657               2.563   \n",
       "742                 3.286               9.392               3.142   \n",
       "\n",
       "     11719828_x_at_QPCT  11750143_a_at_PIGZ  11732501_a_at_TMOD1  \n",
       "0                 9.176               2.229                6.533  \n",
       "1                 8.711               1.998                5.096  \n",
       "2                 9.201               2.223                5.210  \n",
       "3                 8.706               2.570                8.093  \n",
       "8                 8.694               2.319                6.090  \n",
       "..                  ...                 ...                  ...  \n",
       "730               8.400               2.279                7.605  \n",
       "731               9.109               2.180                6.971  \n",
       "732               8.842               2.601                6.792  \n",
       "734               8.893               2.389                5.906  \n",
       "742               8.212               2.619                5.389  \n",
       "\n",
       "[303 rows x 53 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Gene_expr.dropna(subset=['PTGENDER'])\n",
    "print(Counter(df.DX_bl))\n",
    "df = df[(df['DX_bl']=='AD') | (df['DX_bl']=='CN')]\n",
    "y = df.DX_bl\n",
    "df = df.drop(columns=['Unnamed: 0','DX_bl'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col_index = [0,2] + list(range(3,3+N))\n",
    "cat_col_index = [1]\n",
    "num_col = list(df.iloc[:,num_col_index].columns)\n",
    "cat_col = list(df.iloc[:,cat_col_index].columns)\n",
    "df[num_col] = df[num_col].fillna(value=df[num_col].mean())\n",
    "\n",
    "#df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6545726495726495\n",
      "0.8198290598290601\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def train_scaler(data,num_col_index):\n",
    "    scaled_features = data.copy()\n",
    "    features = scaled_features.iloc[:,num_col_index]\n",
    "    scaler = StandardScaler().fit(features.values)\n",
    "    features = scaler.transform(features.values)\n",
    "    scaled_features.iloc[:,num_col_index] = features\n",
    "    return scaler, scaled_features\n",
    "    \n",
    "def test_scaler(scaler,data,num_col_index):\n",
    "    scaled_features = data.copy()\n",
    "    features = scaled_features.iloc[:,num_col_index]\n",
    "    features = scaler.transform(features.values)\n",
    "    scaled_features.iloc[:,num_col_index] = features\n",
    "    \n",
    "    return scaled_features\n",
    "\n",
    "# prepare categorical input data\n",
    "def prepare_cat(X):\n",
    "    oe = OneHotEncoder()\n",
    "    oe.fit(X)\n",
    "    X_enc = oe.transform(X)\n",
    "    return X_enc\n",
    " \n",
    "# prepare target\n",
    "def prepare_targets(y):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y)\n",
    "    y = le.transform(y)\n",
    "    return y\n",
    "\n",
    "def data_prep(X_train,y_train,X_test,y_test,num_col_index, cat_col_index,preprocessing='none'):\n",
    "    \n",
    "    if preprocessing == 'none':\n",
    "        # One hot encoding of categorical variable\n",
    "        combined_data = pd.concat([X_train.iloc[:,cat_col_index], X_test.iloc[:,cat_col_index]], ignore_index=True)\n",
    "        combined_data_cat = prepare_cat(combined_data)\n",
    "        X_train_cat = combined_data_cat[0:len(X_train),:]\n",
    "        X_test_cat = combined_data_cat[len(X_train):,:]\n",
    "\n",
    "        #Concatenation of numerical and categorical inputs\n",
    "        X_train_final = hstack((X_train_cat,X_train.iloc[:,num_col_index]))\n",
    "        X_test_final = hstack((X_test_cat,X_test.iloc[:,num_col_index]))\n",
    "\n",
    "\n",
    "        # Binarization of target label\n",
    "        y_train_final = prepare_targets(y_train)\n",
    "        y_test_final = prepare_targets(y_test)\n",
    "\n",
    "\n",
    "        return X_train_final,y_train_final,X_test_final,y_test_final\n",
    "        \n",
    "    else:\n",
    "        #Oversample the minority class \n",
    "        smt = SMOTENC(categorical_features =cat_col_index, \n",
    "                    random_state=123,\n",
    "                    k_neighbors=7,\n",
    "                    sampling_strategy=float(0.6)\n",
    "                         )\n",
    "        X_trainres,y_trainres = smt.fit_resample(X_train,y_train) #Oversampled training set\n",
    "\n",
    "        # Standard Scaling of numeric variable\n",
    "        scaler, X_trainres_scaled = train_scaler(X_trainres,num_col_index)\n",
    "        X_test_scaled = test_scaler(scaler,X_test,num_col_index)\n",
    "\n",
    "        # One hot encoding of categorical variable\n",
    "        combined_data = pd.concat([X_trainres_scaled.iloc[:,cat_col_index], X_test_scaled.iloc[:,cat_col_index]], ignore_index=True)\n",
    "        combined_data_cat = prepare_cat(combined_data)\n",
    "        X_train_cat = combined_data_cat[0:len(X_trainres_scaled),:]\n",
    "        X_test_cat = combined_data_cat[len(X_trainres_scaled):,:]\n",
    "\n",
    "        #Concatenation of numerical and categorical inputs\n",
    "        X_train_final = hstack((X_train_cat,X_trainres_scaled.iloc[:,num_col_index]))\n",
    "        X_test_final = hstack((X_test_cat,X_test_scaled.iloc[:,num_col_index]))\n",
    "\n",
    "\n",
    "        # Binarization of target label\n",
    "        y_train_final = prepare_targets(y_trainres)\n",
    "        y_test_final = prepare_targets(y_test)\n",
    "\n",
    "\n",
    "        return X_train_final,y_train_final,X_test_final,y_test_final\n",
    "\n",
    "\n",
    "def classifier(name,n_estimators=100):\n",
    "    if name == 'RandomForestClassifier':\n",
    "        return RandomForestClassifier(n_estimators=n_estimators,criterion='gini',class_weight='balanced',random_state=1)\n",
    "    \n",
    "    if name == 'GradientBoosting':\n",
    "        return GradientBoostingClassifier(n_estimators=n_estimators,random_state=1)\n",
    "    \n",
    "    else:\n",
    "        raise NotImplementedError(\"This classifier is not implemented yet. Please choose from [RandomForest, GradientBoosting]\")\n",
    "\n",
    "        \n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "X = df\n",
    "acc = []\n",
    "f1 = []\n",
    "auc = []\n",
    "imp = []\n",
    "for train, test in cv.split(df, y):\n",
    "    X_train = X.iloc[train]\n",
    "    y_train = y.iloc[train]\n",
    "    \n",
    "    X_test = X.iloc[test]\n",
    "    y_test = y.iloc[test]\n",
    "\n",
    "    X_train_final,y_train_final,X_test_final,y_test_final = data_prep(X_train,y_train,X_test,y_test,num_col_index, cat_col_index)\n",
    "    n_estimators = 1000\n",
    "    model = classifier('GradientBoosting', n_estimators)\n",
    "    probas_ = model.fit(X_train_final, y_train_final).predict_proba(X_test_final)\n",
    "    y_pred = model.predict(X_test_final)\n",
    "    acc.append(balanced_accuracy_score(y_test_final, y_pred))\n",
    "    f1.append(f1_score(y_test_final, y_pred, average='macro'))\n",
    "    auc.append(roc_auc_score(y_test_final, probas_[:, 1]))\t    \t\n",
    "    imp.append(model.feature_importances_)\n",
    "print(sum(acc)/len(acc))\n",
    "print(sum(auc)/len(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The StandardScaler() should be correctly used, It caused significant data leakage issue.\n",
    "\n",
    "SMOTENC and StandardScaler() combined rather worsen the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
